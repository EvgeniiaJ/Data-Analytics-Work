{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 Support Vector Machine and Decision Trees\n",
    "\n",
    "# Due on 11/30 23:59 pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will use the same affair dataset from HW2, but will skip the EDA phrase we have done enough of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Everything removing outliers, create dummies variabes had been done for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate_marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>yrs_married</th>\n",
       "      <th>children</th>\n",
       "      <th>religious</th>\n",
       "      <th>educ</th>\n",
       "      <th>had_affair</th>\n",
       "      <th>occ2</th>\n",
       "      <th>occ3</th>\n",
       "      <th>occ4</th>\n",
       "      <th>occ5</th>\n",
       "      <th>occ6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate_marriage   age  yrs_married  children  religious  educ  had_affair  \\\n",
       "0            3.0  32.0          9.0       3.0        3.0  17.0           1   \n",
       "1            3.0  27.0         13.0       3.0        1.0  14.0           1   \n",
       "2            4.0  22.0          2.5       0.0        1.0  16.0           1   \n",
       "3            4.0  37.0         16.5       4.0        3.0  16.0           1   \n",
       "4            5.0  27.0          9.0       1.0        1.0  14.0           1   \n",
       "\n",
       "   occ2  occ3  occ4  occ5  occ6  \n",
       "0     1     0     0     0     0  \n",
       "1     0     1     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     1     0  \n",
       "4     0     1     0     0     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember the affair data set from HW3, we will use that dataset again\n",
    "# but we will directly load from file\n",
    "orig_df = pd.read_csv(\"affairs2.csv\")\n",
    "# Set up our target class label\n",
    "orig_df['had_affair'] = orig_df['affairs'].apply(lambda x: 1 if x != 0 else 0)\n",
    "orig_df = orig_df.drop('affairs',axis=1)\n",
    "# remove NA\n",
    "orig_df.dropna(inplace=True)\n",
    "# create dummies variable for occupation\n",
    "occ = pd.get_dummies(orig_df['occupation'],drop_first=True)\n",
    "# we include rate_marriage feature as well. In HW3, we did not include that variable\n",
    "features = ['rate_marriage','age','yrs_married','children','religious','educ', 'had_affair']\n",
    "df = orig_df\n",
    "df = pd.concat([orig_df[features], occ], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rate_marriage    0\n",
       "age              0\n",
       "yrs_married      0\n",
       "children         0\n",
       "religious        0\n",
       "educ             0\n",
       "had_affair       0\n",
       "occ2             0\n",
       "occ3             0\n",
       "occ4             0\n",
       "occ5             0\n",
       "occ6             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure there is no missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are ready to build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Build a classification model using SVC using linear kernel with usual steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3. , 32. ,  9. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 3. , 27. , 13. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 4. , 22. ,  2.5, ...,  0. ,  0. ,  0. ],\n",
       "       ...,\n",
       "       [ 5. , 22. ,  2.5, ...,  0. ,  0. ,  0. ],\n",
       "       [ 5. , 32. ,  6. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 4. , 22. ,  2.5, ...,  0. ,  0. ,  0. ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separate the data set into two sets: set of features and a set of taarget varibles\n",
    "X = df.to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df['had_affair'].to_numpy()\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the model from sklearn import svm, create the SVC object \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call Train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.drop('had_affair', axis = 1), df['had_affair'], test_size = 0.2, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = svm.SVC()\n",
    "model_1 = svm.SVC(kernel = 'linear', C=1)\n",
    "model_1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_y_pred = model_1.predict(X_test)\n",
    "model_1_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[797  56]\n",
      " [303 118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.82       853\n",
      "           1       0.68      0.28      0.40       421\n",
      "\n",
      "    accuracy                           0.72      1274\n",
      "   macro avg       0.70      0.61      0.61      1274\n",
      "weighted avg       0.71      0.72      0.68      1274\n",
      "\n",
      "0.7182103610675039\n"
     ]
    }
   ],
   "source": [
    "#print out model performance\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "model_1_predictions = model_1.predict(X_test)\n",
    "print(confusion_matrix(Y_test, model_1_predictions))\n",
    "print(classification_report(Y_test, model_1_predictions))\n",
    "print(accuracy_score(Y_test, model_1_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2. Now try different value of C-parameter and rerun your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try C = 2**-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.03125, kernel='linear')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = svm.SVC(kernel='linear', C = 2**-5)\n",
    "model_2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_y_pred = model_2.predict(X_test)\n",
    "model_2_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[799  54]\n",
      " [308 113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.82       853\n",
      "           1       0.68      0.27      0.38       421\n",
      "\n",
      "    accuracy                           0.72      1274\n",
      "   macro avg       0.70      0.60      0.60      1274\n",
      "weighted avg       0.71      0.72      0.67      1274\n",
      "\n",
      "0.7158555729984302\n"
     ]
    }
   ],
   "source": [
    "model_2_predictions = model_2.predict(X_test)\n",
    "print(confusion_matrix(Y_test, model_2_predictions))\n",
    "print(classification_report(Y_test, model_2_predictions))\n",
    "print(accuracy_score(Y_test, model_2_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try C = 2**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=32, kernel='linear')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = svm.SVC(kernel='linear', C = 2**5)\n",
    "model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_y_pred = model_2.predict(X_test)\n",
    "model_3_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[797  56]\n",
      " [302 119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.82       853\n",
      "           1       0.68      0.28      0.40       421\n",
      "\n",
      "    accuracy                           0.72      1274\n",
      "   macro avg       0.70      0.61      0.61      1274\n",
      "weighted avg       0.71      0.72      0.68      1274\n",
      "\n",
      "0.7189952904238619\n"
     ]
    }
   ],
   "source": [
    "model_3_predictions = model_3.predict(X_test)\n",
    "print(confusion_matrix(Y_test, model_3_predictions))\n",
    "print(classification_report(Y_test, model_3_predictions))\n",
    "print(accuracy_score(Y_test, model_3_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3. Try using rbf as your kernel and use Gamma of 2**-5, 0.1, 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma=0.03125)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model with rbf for kernel and 2^(-5) for Gamma\n",
    "kernel_model_1 = svm.SVC(kernel='rbf', gamma = 2**-5)\n",
    "kernel_model_1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_kernel1_pred = kernel_model_1.predict(X_test)\n",
    "y_kernel1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[786  67]\n",
      " [288 133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.92      0.82       853\n",
      "           1       0.67      0.32      0.43       421\n",
      "\n",
      "    accuracy                           0.72      1274\n",
      "   macro avg       0.70      0.62      0.62      1274\n",
      "weighted avg       0.71      0.72      0.69      1274\n",
      "\n",
      "0.7213500784929356\n"
     ]
    }
   ],
   "source": [
    "kernel_model_1_predictions = kernel_model_1.predict(X_test)\n",
    "print(confusion_matrix(Y_test, kernel_model_1_predictions))\n",
    "print(classification_report(Y_test, kernel_model_1_predictions))\n",
    "print(accuracy_score(Y_test, kernel_model_1_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with rbf for kernel and 0.1 for Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma=0.1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_model_2 = svm.SVC(kernel='rbf', gamma = 0.1)\n",
    "kernel_model_2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_kernel2_pred = kernel_model_2.predict(X_test)\n",
    "y_kernel2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[777  76]\n",
      " [278 143]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.81       853\n",
      "           1       0.65      0.34      0.45       421\n",
      "\n",
      "    accuracy                           0.72      1274\n",
      "   macro avg       0.69      0.63      0.63      1274\n",
      "weighted avg       0.71      0.72      0.69      1274\n",
      "\n",
      "0.7221350078492935\n"
     ]
    }
   ],
   "source": [
    "kernel_model_2_predictions = kernel_model_2.predict(X_test)\n",
    "print(confusion_matrix(Y_test, kernel_model_2_predictions))\n",
    "print(classification_report(Y_test, kernel_model_2_predictions))\n",
    "print(accuracy_score(Y_test, kernel_model_2_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with rbf for kernel and 1 for Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_model_3 = svm.SVC(kernel='rbf', gamma = 1)\n",
    "kernel_model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_kernel3_pred = kernel_model_3.predict(X_test)\n",
    "y_kernel3_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[770  83]\n",
      " [325  96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.90      0.79       853\n",
      "           1       0.54      0.23      0.32       421\n",
      "\n",
      "    accuracy                           0.68      1274\n",
      "   macro avg       0.62      0.57      0.56      1274\n",
      "weighted avg       0.65      0.68      0.64      1274\n",
      "\n",
      "0.6797488226059655\n"
     ]
    }
   ],
   "source": [
    "kernel_model_3_predictions = kernel_model_3.predict(X_test)\n",
    "print(confusion_matrix(Y_test, kernel_model_3_predictions))\n",
    "print(classification_report(Y_test, kernel_model_3_predictions))\n",
    "print(accuracy_score(Y_test, kernel_model_3_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with rbf for kernel and 2 for Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_model_4 = svm.SVC(kernel='rbf', gamma = 2)\n",
    "kernel_model_4.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_kernel4_pred = kernel_model_4.predict(X_test)\n",
    "y_kernel4_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[781  72]\n",
      " [371  50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.92      0.78       853\n",
      "           1       0.41      0.12      0.18       421\n",
      "\n",
      "    accuracy                           0.65      1274\n",
      "   macro avg       0.54      0.52      0.48      1274\n",
      "weighted avg       0.59      0.65      0.58      1274\n",
      "\n",
      "0.652276295133438\n"
     ]
    }
   ],
   "source": [
    "kernel_model_4_predictions = kernel_model_4.predict(X_test)\n",
    "print(confusion_matrix(Y_test, kernel_model_4_predictions))\n",
    "print(classification_report(Y_test, kernel_model_4_predictions))\n",
    "print(accuracy_score(Y_test, kernel_model_4_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4. So out of all the models you try in Question 2 and 3, what is the best choice for the kernel, C and gamma parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Linear</strong> kernel is better in comparison with <em>Radial Basis Function</em> according to the performance of the models obtained above. Since we have only two classes, we it is enough to use linear kernel to get proper results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C parameter is the penalty representing misclassification or error. A small value of C creates a small-margin hyperplane and a larger value of C creates a lerger-marging hyperplane. Based on the results obtained above, the largest value of C, in our case it is <strong>32 (2^5)</strong>, is the best choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case there are two best value for gamma. They are <strong>2^(-5)</strong> and <strong>0.1</strong>. Yet, it considers only nearby points in calculating the separation line in contrast to the large values of gamma that consider all the data points in the calculation of the separation line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will try to fit the same dataset with Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5. Build a Decision Tree Classifier using default parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[676 177]\n",
      " [275 146]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75       853\n",
      "           1       0.45      0.35      0.39       421\n",
      "\n",
      "    accuracy                           0.65      1274\n",
      "   macro avg       0.58      0.57      0.57      1274\n",
      "weighted avg       0.63      0.65      0.63      1274\n",
      "\n",
      "0.6452119309262166\n"
     ]
    }
   ],
   "source": [
    "model_default_predictions = model.predict(X_test)\n",
    "print(confusion_matrix(Y_test, model_default_predictions))\n",
    "print(classification_report(Y_test, model_default_predictions))\n",
    "print(accuracy_score(Y_test, model_default_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6. Now try using max_depth = 2, 3, 4 and crierion = 'gini' and 'entropy' to build 3 X 2 = 6 different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[772  81]\n",
      " [279 142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81       853\n",
      "           1       0.64      0.34      0.44       421\n",
      "\n",
      "    accuracy                           0.72      1274\n",
      "   macro avg       0.69      0.62      0.63      1274\n",
      "weighted avg       0.70      0.72      0.69      1274\n",
      "\n",
      "0.717425431711146\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with max depth = 2 and GINI for criterion\n",
    "g2_model = DecisionTreeClassifier(criterion = 'gini', max_depth = 2)\n",
    "g2_model.fit(X_train,Y_train)\n",
    "g2_model_predictions = g2_model.predict(X_test)\n",
    "print(confusion_matrix(Y_test, g2_model_predictions))\n",
    "print(classification_report(Y_test, g2_model_predictions))\n",
    "print(accuracy_score(Y_test, g2_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[772  81]\n",
      " [279 142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81       853\n",
      "           1       0.64      0.34      0.44       421\n",
      "\n",
      "    accuracy                           0.72      1274\n",
      "   macro avg       0.69      0.62      0.63      1274\n",
      "weighted avg       0.70      0.72      0.69      1274\n",
      "\n",
      "0.717425431711146\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with max depth = 2 and ENTROPY for criterion\n",
    "e2_model = DecisionTreeClassifier(criterion = 'entropy', max_depth = 2)\n",
    "e2_model.fit(X_train,Y_train)\n",
    "e2_model_predictions = e2_model.predict(X_test)\n",
    "print(confusion_matrix(Y_test, e2_model_predictions))\n",
    "print(classification_report(Y_test, e2_model_predictions))\n",
    "print(accuracy_score(Y_test, e2_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[787  66]\n",
      " [298 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.92      0.81       853\n",
      "           1       0.65      0.29      0.40       421\n",
      "\n",
      "    accuracy                           0.71      1274\n",
      "   macro avg       0.69      0.61      0.61      1274\n",
      "weighted avg       0.70      0.71      0.68      1274\n",
      "\n",
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with max depth = 3 and GINI for criterion\n",
    "g3_model = DecisionTreeClassifier(criterion = 'gini', max_depth = 3)\n",
    "g3_model.fit(X_train,Y_train)\n",
    "g3_model_predictions = g3_model.predict(X_test)\n",
    "print(confusion_matrix(Y_test, g3_model_predictions))\n",
    "print(classification_report(Y_test, g3_model_predictions))\n",
    "print(accuracy_score(Y_test, g3_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[787  66]\n",
      " [298 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.92      0.81       853\n",
      "           1       0.65      0.29      0.40       421\n",
      "\n",
      "    accuracy                           0.71      1274\n",
      "   macro avg       0.69      0.61      0.61      1274\n",
      "weighted avg       0.70      0.71      0.68      1274\n",
      "\n",
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with max depth = 3 and ENTROPY for criterion\n",
    "e3_model = DecisionTreeClassifier(criterion = 'entropy', max_depth = 3)\n",
    "e3_model.fit(X_train,Y_train)\n",
    "e3_model_predictions = e3_model.predict(X_test)\n",
    "print(confusion_matrix(Y_test, e3_model_predictions))\n",
    "print(classification_report(Y_test, e3_model_predictions))\n",
    "print(accuracy_score(Y_test, e3_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[772  81]\n",
      " [282 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81       853\n",
      "           1       0.63      0.33      0.43       421\n",
      "\n",
      "    accuracy                           0.72      1274\n",
      "   macro avg       0.68      0.62      0.62      1274\n",
      "weighted avg       0.70      0.72      0.69      1274\n",
      "\n",
      "0.7150706436420722\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with max depth = 4 and GINI for criterion\n",
    "g4_model = DecisionTreeClassifier(criterion = 'gini', max_depth = 4)\n",
    "g4_model.fit(X_train,Y_train)\n",
    "g4_model_predictions = g4_model.predict(X_test)\n",
    "print(confusion_matrix(Y_test, g4_model_predictions))\n",
    "print(classification_report(Y_test, g4_model_predictions))\n",
    "print(accuracy_score(Y_test, g4_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[772  81]\n",
      " [282 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81       853\n",
      "           1       0.63      0.33      0.43       421\n",
      "\n",
      "    accuracy                           0.72      1274\n",
      "   macro avg       0.68      0.62      0.62      1274\n",
      "weighted avg       0.70      0.72      0.69      1274\n",
      "\n",
      "0.7150706436420722\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with max depth = 4 and ENTROPY for criterion\n",
    "e4_model = DecisionTreeClassifier(criterion = 'entropy', max_depth = 4)\n",
    "e4_model.fit(X_train,Y_train)\n",
    "e4_model_predictions = e4_model.predict(X_test)\n",
    "print(confusion_matrix(Y_test, e4_model_predictions))\n",
    "print(classification_report(Y_test, e4_model_predictions))\n",
    "print(accuracy_score(Y_test, e4_model_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7. What is your obsevation from Question 6? Does the choice of the criterion important in this case? What about the max_depth? What is the best choice of max_depth and criterion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Since performance of models using gini and entropy for criterion are identical for each model with the same depth, the choice of criterion does not make a difference in performance.\n",
    "\n",
    "As for the value of depth, the best performance is obtained with the value of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Visualization\n",
    "\n",
    "Scikit learn actually has some built-in visualization capabilities for decision trees, you won't use this often and it requires you to install the pydot library, but here is an example of what it looks like and the code to execute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rate_marriage', 'age', 'yrs_married', 'children', 'religious', 'educ',\n",
       "       'had_affair', 'occ2', 'occ3', 'occ4', 'occ5', 'occ6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rate_marriage',\n",
       " 'age',\n",
       " 'yrs_married',\n",
       " 'children',\n",
       " 'religious',\n",
       " 'educ',\n",
       " 'had_affair']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.externals.six import StringIO\n",
    "from six import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rate_marriage',\n",
       " 'age',\n",
       " 'yrs_married',\n",
       " 'children',\n",
       " 'religious',\n",
       " 'educ',\n",
       " 'occ2',\n",
       " 'occ3',\n",
       " 'occ4',\n",
       " 'occ5',\n",
       " 'occ6']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image  \n",
    "# from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "import io\n",
    "import pydot \n",
    "\n",
    "# Pick up all featurs columns from your data frame\n",
    "features = list(df.drop(['had_affair'],axis=1).columns)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general tree representation\n",
    "dot_data = StringIO()\n",
    "export_graphviz(model, out_file=dot_data, feature_names=features)\n",
    "(graph, ) = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8, now pick three models, with max_depth = 2, 3 and 4. You can pick the which ever criterions you want and visual the three trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree with depth 2 and entropy for criterion\n",
    "dot_data = StringIO()\n",
    "export_graphviz(e2_model, out_file=dot_data, feature_names=features, filled=True, rounded = True)\n",
    "(graph, ) = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree with depth 3 and gini for criterion\n",
    "dot_data = StringIO()\n",
    "export_graphviz(g3_model, out_file=dot_data, feature_names=features, filled=True, rounded = True)\n",
    "(graph, ) = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree with depth 2 and entropy for criterion\n",
    "dot_data = StringIO()\n",
    "export_graphviz(e4_model, out_file=dot_data, feature_names=features, filled=True, rounded = True)\n",
    "(graph, ) = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9. Now build a Random Forest Classifier with, say, 100 trees. Check the model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators = 100)\n",
    "rfc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = rfc.predict(X_test)\n",
    "print(classification_report(Y_test, e2_model_predictions))\n",
    "print(accuracy_score(Y_test, e2_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, g3_model_predictions))\n",
    "print(accuracy_score(Y_test, g3_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, e4_model_predictions))\n",
    "print(accuracy_score(Y_test, e4_model_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest for model with tree depth = 2 and entropy for criterion displays the best model performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
